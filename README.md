# Intelligent Web-Crawler and Query Engine

A Flask-based web application for crawling AP Agriculture websites and performing semantic search using OpenAI embeddings.

## Features

- ğŸŒ Web crawling of AP Agriculture websites
- ğŸ“„ PDF document processing
- ğŸ” Semantic search using OpenAI embeddings
- ğŸ’¾ SQLite database storage
- ğŸ¨ Modern web interface
- âš¡ Caching for improved performance

## Setup Instructions

1. **Install required packages:**
   ```bash
   pip install -r requirements.txt
   ```

2. **Create a .env file with your OpenAI API key:**
   ```
   OPENAI_API_KEY=sk-your-actual-openai-key-here
   ```

3. **Run the application:**
   ```bash
   python app.py
   ```

4. **Visit the application:**
   Open your browser and go to `http://127.0.0.1:8080`

## Project Structure

```
crawler2/
â”œâ”€â”€ app.py                 # Main Flask application
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ README.md             # This file
â”œâ”€â”€ .env                  # Environment variables (create this)
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py       # Configuration settings
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ models.py         # Database operations
â”œâ”€â”€ crawler/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ crawler.py        # Web crawling logic
â”‚   â””â”€â”€ parser.py         # Content parsing utilities
â”œâ”€â”€ search/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ vector_store.py   # Vector search operations
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ style.css     # Stylesheets
â”‚   â””â”€â”€ js/
â”‚       â””â”€â”€ main.js       # JavaScript functionality
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html        # Main HTML template
â””â”€â”€ downloads/            # Downloaded files (auto-created)
```

## Usage

1. **Initial Setup:** Click "Re-crawl Websites" to populate the database with content from AP Agriculture websites
2. **Search:** Use the search bar to find information about crops, schemes, policies, etc.
3. **Results:** View relevant documents with relevance scores and direct links to sources

## Configuration

Key settings can be modified in `config/settings.py`:
- Seed URLs for crawling
- Maximum pages to crawl
- Thread count for parallel processing
- Timeout settings

## API Endpoints

- `GET /` - Main application interface
- `POST /crawl` - Trigger web crawling
- `GET /search?query=<text>` - Perform semantic search
- `GET /status` - Application status and statistics

## Technologies Used

- **Backend:** Flask, SQLite
- **Crawling:** Requests, BeautifulSoup, PyPDF2
- **AI:** OpenAI Embeddings API
- **Frontend:** HTML5, CSS3, JavaScript
- **Caching:** Flask-Caching # Crawler
